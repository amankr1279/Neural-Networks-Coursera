{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+ math.exp(-x))\n",
    "\n",
    "sigmoid(3)\n",
    "some_arr = []\n",
    "for i in range(1,100):\n",
    "    some_arr.append(sigmoid(i))\n",
    "\n",
    "plt.plot(some_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_sigmoid(x):\n",
    "    return 1/(1+ np.exp(-x))\n",
    "\n",
    "a = np.array([i for i in range(-20,20)])\n",
    "plt.plot(vector_sigmoid(a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid Gradient\n",
    "\n",
    "sig`(x) = sig(x)*(1-sig(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    s = vector_sigmoid(x)\n",
    "    ds = s*(1-s)\n",
    "    return ds\n",
    "\n",
    "print(sigmoid_derivative(a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image to vector\n",
    "\n",
    "involves reshaping of matrices and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_vec(path):\n",
    "    img = Image.open(path)\n",
    "    img = np.array(img)\n",
    "    l,b,h = img.shape\n",
    "    img = img.reshape(l * b * h, 1)\n",
    "    return img\n",
    "\n",
    "img = image_to_vec(\"images/backgnd_pic.jpeg\")\n",
    "# print(img.shape)\n",
    "\n",
    "def normalize(x):\n",
    "    x_norm = np.linalg.norm(x,keepdims=True)\n",
    "    return x/x_norm\n",
    "\n",
    "img = normalize(img)\n",
    "print(\"Normalized img :\", img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax\n",
    "\n",
    "it is a normalization function used for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmaxRows(x):\n",
    "    x_exp = np.exp(x)\n",
    "    x_sums = np.sum(x_exp,axis=1, keepdims=True)\n",
    "    x_softmax = x_exp/x_sums\n",
    "    return x_softmax\n",
    "\n",
    "x = np.array([\n",
    "    [9, 2, 5, 0, 0],\n",
    "    [7, 5, 0, 0 ,0]])\n",
    "print(\"softmaxRows(x) = \" + str(softmaxRows(x)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss functions \n",
    "* L1 : abs loss \n",
    "* L2 : squares loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1_loss(y, yhat):\n",
    "    return sum(abs(y-yhat))\n",
    "\n",
    "def L2_loss(y,yhat):\n",
    "    return np.dot(y-yhat, y-yhat)\n",
    "\n",
    "y = np.array([1,2,3])\n",
    "yhat=np.array([1.01, 1.99, 3.05])\n",
    "print(\"L1 : \",L1_loss(y,yhat))\n",
    "print(\"L2 : \",L2_loss(y,yhat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
